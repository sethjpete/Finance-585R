{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin 585R**  \n",
    "**Diether**  \n",
    "**Python/Pandas Introduction**<br><br>\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "+ Please read through my notes, and run each of the code cells.<br><br> \n",
    "\n",
    "+ You can run a cell of code by pressing SHIFT and ENTER at the same time.<br><br>\n",
    "\n",
    "\n",
    "**I. Python/Pandas in Empirical Finance**\n",
    "\n",
    "**A. Role of Python/Pandas in this Course**\n",
    "\n",
    "+ Goal: Develop the Python/Pandas skills and tools necessary to engage in empirical research in Finance.<br><br>  \n",
    "\n",
    "+ More specifically: use Python/Pandas to<br><br>\n",
    "\n",
    "  - Test economic models<br><br>\n",
    "  \n",
    "  - Construct portfolios (container for financial assets)<br><br>\n",
    "  \n",
    "  - Create and backtest trading strategies.<br><br>\n",
    "  \n",
    "  - Estimate regressions: time series and panel regressions.<br><br>\n",
    "  \n",
    "+ I will focus on the most important features and programming constructs in Python/Pandas to accomplish goal.<br><br>\n",
    "\n",
    "\n",
    "**B. Example: Portfolio Construction and Trading Strategies**\n",
    "\n",
    "+ A core quant finance and academic skill is portfolio construction and backtesting.<br><br>\n",
    "\n",
    "+ All trading strategies are implemented as portfolios (container for financial assets).<br><br>\n",
    "\n",
    "+ Portfolio construction and backtesting can be broken into five general steps:<br>\n",
    "\n",
    "  1. Data preparation.<br><br>\n",
    "\n",
    "  2. Creation of the portfolio formation variable.<br><br>\n",
    "\n",
    "  3. Binning the stock return data based the formation variable.<br><br>\n",
    "\n",
    "  4. Portfolio creation.<br><br>\n",
    "\n",
    "  5. Estimating historical performance of the strategy.<br><br>\n",
    "\n",
    "+ Need to learn enough Python/Pandas so you can tackle each step for portfolio strategies you're interested in testing.<br><br>\n",
    "\n",
    "\n",
    "**II. Why Python/Pandas?**\n",
    "\n",
    "+ Why Python/Pandas? Why not Stata, R, SAS, or something else?<br><br>\n",
    "\n",
    "+ All of those languages are used in empirical finance research.<br><br>\n",
    "\n",
    "+ Python/Pandas has some important advantages:<br><br>\n",
    "\n",
    "  - Very popular in finance world now.<br><br>\n",
    "\n",
    "  - Well designed and popular general purpose programming language.<br><br>\n",
    "  \n",
    "  - Free<br><br>\n",
    "  \n",
    "  - Relatively easily to learn. <br><br>\n",
    "  \n",
    "  - Used in lots of different domains; it's not narrowly confined to the domain of quantitative finance or even scientific computing or data science.<br><br>\n",
    "  \n",
    "\n",
    "**III. Overview of Basic Concepts and Features**\n",
    "\n",
    "+ Main purpose of this `notebook` is to introduce the `Pandas` `library`.<br><br>\n",
    "\n",
    "+ `Pandas` is the main library for this course.<br><br>\n",
    "\n",
    "+ Will overview core concepts and features of `pandas` for quant and academic finance.<br><br>\n",
    "\n",
    "+ Will cover the concepts and features with more detail as we move forward.<br><br>\n",
    "\n",
    "\n",
    "**A. Accessing the Pandas Library**\n",
    "\n",
    "+ To use the Pandas library we have to tell Python that we want access to it.<br><br>\n",
    "\n",
    "+ You make `pandas` accessible by using the `import` command.<br><br>\n",
    "\n",
    "+ When importing the pandas' library, you also associate the library with a namespace: **use pd**<br><br>\n",
    "\n",
    "  - Just convention<br><br>\n",
    "\n",
    "  - Given the `pd` namespace $\\rightarrow$ Pandas' functions looke like `pd.function`.<br><br>\n",
    "  \n",
    "  - For example, `pd.read_csv`. <br><br>\n",
    "\n",
    "  - `pd` namespace is not required, but is a strong convention.<br><br>\n",
    "\n",
    "  - Namespaces make it clear what library a certain function or command comes from if each library you use has it's own namespace.<br><br>\n",
    "\n",
    "\n",
    "+ **code to importing pandas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**B. Pandas core Data Structures: Dataframes and Series**\n",
    "\n",
    "+ Core data structure/object: the **dataframe**.<br><br>\n",
    "\n",
    "+ Dataframe: container for holding rectangular array of mixed type data called a `dataframe`.<br><br>\n",
    "\n",
    "  - Columns: represent different variables (e.g, the stock price or earnings of Google).<br><br>\n",
    "\n",
    "  - Rows: represent a given observation for those variables (e.g., January 2009 for Google).<br><br>\n",
    "\n",
    "+ Dataframe: programming equivalent of a spreadsheet.<br><br> \n",
    "\n",
    "+ Each column can be of a different type: integers, floating point numbers, imaginary numbers, or strings. <br><br>\n",
    "\n",
    "\n",
    "**Dataframes: Store Data and Provide Useful Functions**\n",
    "\n",
    "+ Pandas' provides programmers with many ways to create new data, transform and combine data, aggregate data, or display data. <br><br>\n",
    "\n",
    "  - Example: Pandas' has a built in operator (`/`) that allows you to divide one column into the other column element by element.<br><br>\n",
    "\n",
    "  - Example: Built in mean function that computes sample average of each column.<br><br>\n",
    "  \n",
    "  - Higher level functions that, allow us to easily create graphs or plots of data.<br><br>\n",
    "  \n",
    "+ Many of functions are built into the dataframe.<br><br>\n",
    "\n",
    "+ Built in functions called `methods`.<br><br>\n",
    "\n",
    "+ Dataframe is an object the provides data storage and useful functions<br><br>\n",
    "\n",
    "\n",
    "**Series**\n",
    "\n",
    "+ `Series` in pandas' is the name for a single column of data.<br><br>\n",
    "  \n",
    "+ If you grab one column of a dataframe, you're grabbing a series.<br><br>\n",
    "\n",
    "+ `Dataframes` and `Series` behave very similarly; for our purposes, it is mostly just be a technical distinction between a one dimensional and two dimensional array.<br><br>\n",
    "\n",
    "\n",
    "**C. Importing Data and Creating a DataFrame:**\n",
    "\n",
    "+ Getting data into a `Pandas'` dataframe is usually straight forward and easy. <br><br>\n",
    "\n",
    "+ Pandas easily reads many different data formats: csv files, Excel files, SAS data files, Stata data files, Feather data files, etc.<br><br>\n",
    "\n",
    "+ In this class, we will primarily use csv files.<br><br>\n",
    "\n",
    "+ I will highlight other methods.<br><br>\n",
    "\n",
    "**Example: Reading in Amazon Data**\n",
    "\n",
    "+ Let's read in some data, and create a `dataframe` object.<br><br> \n",
    "\n",
    "+ The data we will to read into a `dataframe` are annual balance sheet data for Amazon and Hormel.<br><br>\n",
    "\n",
    "+ The data are in a csv file so we can read in the data using the `read_csv` function.<br><br>\n",
    "\n",
    "+ The `read_csv` function will automatically create a `dataframe` object containing the data contained in the csv file.<br><br>\n",
    "\n",
    "+ The `read_csv` function has a lot of options and flexibility (take a look at the [help page for it in Pandas' documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)), but often you don't use any of them (particularly for well formed or non-messy csv files). <br><br>\n",
    "\n",
    "+ The `read_csv` function can, of course, read files stored on your local machine, but it also has no trouble reading file stored remotely on a webserver; you just need to provide a URL. <br><br>\n",
    "\n",
    "+ The code below calls pandas' `read_csv` function and then reads the csv located at the URL in quotes. After reading the file it creates a dataframe and assigns the dataframe to `df`.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://diether.org/prephd/01-intro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ To read in data from non-csv formats you generally invoke a command very similar to `read_csv`. For example, you can read in a `Stata` datafile using the following:\n",
    "```python\n",
    "df = pd.read_stata('filename.dta')\n",
    "```\n",
    "\n",
    "+ Many other ways to create dataframes. For example, you can convert core Python data structures (like `lists` or `dictionaries`) into `dataframes`.<br><br> \n",
    "\n",
    "\n",
    "**Displaying or Printing out the Data in a Dataframe**\n",
    "\n",
    "+ The **Jupyter notebook** is a special environment where if you type the name of a dataframe (or other datatypes), it will display the default view of that object (e.g., if the dataframe is small it will display all the data in the dataframe, and if it's large only a truncated view of the data will be displayed). <br><br>\n",
    "\n",
    "+ If you just write a python program and run it outside of the jupyter notebook environment, then you need to use the `print` function to see any output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print function**\n",
    "\n",
    "+ You can also explicitly print a dataframe out using python's print function.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframes and Series**\n",
    "\n",
    "+ Our `dataframe` is called `df`.<br><br>\n",
    "\n",
    "+ If we select a column from the `dataframe` it will be of type `Series`.<br><br>\n",
    "\n",
    "+ We select a column of a dataframe (a Series) by wrapping the column's name in quotes.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['year','revenue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You typically must wrap the column's name in ' ' because most column names are stored as strings.<br><br>\n",
    "\n",
    "+ You will need to reference columns this way as long as the variable names you use aren't entirely numeric (e.g., an integer). <br><br>\n",
    "\n",
    "+ In Python, can delimited by strings either single (' ') or double quotes (\" \"). <br><br>  \n",
    "\n",
    "**Checking the Data Type**\n",
    "\n",
    "+ In Python, there is a `type` function that returns the type of a variable or object. <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**D. Data creation** \n",
    "\n",
    "+ A new column in a dataframe is typically created using the assignment operator.<br><br>\n",
    "\n",
    "+ Like most programming languages, the assignment operator is just the equal sign (`=`) in Python.<br><br>\n",
    "\n",
    "+ For example, suppose I want to create a new column that measure profit margin. Profit margin is defined as the following (note, ebit is earnings before interest and taxes):\n",
    "\n",
    "$$\n",
    "\\text{Profit Margin} = \\frac{ebit}{revenue}\n",
    "$$\n",
    "\n",
    "+ Python/Pandas code for creating profit margin column in the dataframe.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['profit_margin'] = df['ebit'] / df['revenue']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ mathematical operations such as addition (+), subtraction (-), multiplication (*), or division (/) are all element by element operations between the dataframe columns that are addressed by the code.<br><br>\n",
    "\n",
    "\n",
    "**E. If/then/else logic in Pandas:**\n",
    "\n",
    "+ `If/then/else` logic is important in all types of programming.<br><br>\n",
    "\n",
    "+ In `Python/Pandas`, you rarely will write code that looks like classic `if/then/else` statements.<br><br>\n",
    "\n",
    "+ For example, many `Pandas` logical functions or statements are actually `if/then` statements with an implicit else.<br><br>\n",
    "\n",
    "+ Data selection often involves if/then/else logic $\\leftarrow$ in Pandas' jargon it's often called Boleen indexing.<br><br>\n",
    "\n",
    "+ For example, we can use if/then/else logic to create a new variable that is `True` if the year is greater than 2010 and `False` otherwise. The logical statement looks like the following:\n",
    "\n",
    "```\n",
    "if (year is greater than 2010) then\n",
    "   True\n",
    "else\n",
    "   False\n",
    "```\n",
    "\n",
    "+ Using python/pandas the code to implement the preceding logic is the following and it automatically creates a `Series` with `True` and `False` values based on the logical condtion that the year is greater than 2010:<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] > 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We can also assign this new TRUE/FALSE variable to the dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gt_2010'] = df['year'] > 2010\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F. Data selection** \n",
    "\n",
    "+ Based on if/then/else logic `Pandas` allows you to select only the rows or columns of a `dataframe` that you want.<br><br>\n",
    "\n",
    "+ Suppose you only want observations where the year is greater than 2010. Pandas allow us to index a dataframe's rows based on a logical condition or True/False Values.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['gt_2010'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['gt_2010']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['year'] > 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a Sub Dataframe**\n",
    "\n",
    "+ We can assign the smaller dataframe to a new dataframe with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = df[df['year'] > 2010]\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**G. Deleting a Variable/Column of Data**\n",
    "\n",
    "+ Very common to delete or remove columns.<br><br>\n",
    "\n",
    "+ Typically rely on the `drop` function.<br><br>\n",
    "\n",
    "+ For example, suppose I want to drop the `capx` column from the dataframe.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('capx',axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The preceding command, created a new `dataframe` with the `capx` column removed. <br><br>\n",
    "\n",
    "+ Most `pandas` commands operate creating a new datafreame.<br><br>\n",
    "\n",
    "+ To modify the original `dataframe` (df) we have to assign the `dataframe` created by the drop command to `df`.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('capx',axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**IV. More Advanced Concepts and Features**\n",
    "\n",
    "**A. The groupby/apply construct:**. \n",
    "\n",
    "+ The most important **programming idiom** or construct for this class is the `groupby/apply` construct.<br><br>\n",
    "\n",
    "+ Allows us to loop through the data and group observations in a `dataframe` together, and then apply a function or data transformation to each group.<br><br>\n",
    "\n",
    "+ For example, we often use it to group observations by date or to group all the observation of the same stock together. We then typically apply a function to the data that aggregates it or transforms it within these groups.<br><br>\n",
    "\n",
    "+ The `groupby/apply` construct allows us to accomplish the following with just one (or a few lines) of code:\n",
    "\n",
    "  1. Logically **group** observations together based on some attribute of the data: for example, we could group stock data based on whether the company was big or small.<br><br>\n",
    "\n",
    "  2. **Apply** a function to the different groups. For example, we could compute the average number of analysts covering big versus small stocks.<br><br>\n",
    "\n",
    "+ The groupby/apply does a whole bunch of work for us behind the scene. It loops all the observations, categorizes the observations into the groups, and then applies the functions seperately to each group.<br><br>\n",
    "\n",
    "\n",
    "**B. User-written functions:**\n",
    "\n",
    "+ You will write your own custom (i.e., user written) functions to extend the functionality of the `groupby/apply` construct.<br><br>\n",
    "\n",
    "+ For example, writing a custom function is sometimes and important part of implementing a portfolio formation criteria for a trading strategy.<br><br>\n",
    "\n",
    "\n",
    "**C. Merging data:** \n",
    "\n",
    "+ Merging data is a core part of the data preperation step from most empirical work or back testing of strategies.<br><br> \n",
    "\n",
    "+ You will learn how to merge dataframes together based on a single key or multiple keys.<br><br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
